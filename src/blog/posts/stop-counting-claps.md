---
title: Stop Counting Claps
description: DevRel Metrics That Don't Lie.
date: "2025-03-20"
tags: [community, devrel]
---

### The problem isn't that metrics are useless. It's that we pick the wrong job for them.

DevRel attracts two kinds of measurement energy:

1. **The vibes-based approach**
   "Trust me bro, it was a good event."

2. **The marketing-dashboard approach**
   "Look! 84,000 impressions!"

Both are comforting. Both can be wildly misleading.

If you've been in this game long enough, you've watched teams celebrate numbers that had zero relationship with real outcomes. And you've watched genuinely good community work get defunded because it didn't translate cleanly into a spreadsheet.

So here's the thing I wish someone drilled into me earlier:

> **Metrics are not a scoreboard. Metrics are a steering.**

A scoreboard tells you if you "won". A steering tells you if you'll crash.

### The three categories of DevRel metrics (and why most teams get stuck on the first)

Most DevRel reporting accidentally becomes a shrine to **outputs**:

* followers gained
* impressions
* likes
* RSVPs
* attendance count
* number of talks
* number of posts

These aren't *bad*. They're just **not sufficient**.

Outputs tell you activity happened.
They don't tell you whether **momentum** happened.

What we actually care about is a chain:

1. **Outputs** → something you shipped or hosted
2. **Outcomes** → something changed because of it
3. **Compounding** → the change keeps producing change without you pushing as hard

The day you start measuring **compounding**, your entire DevRel strategy matures.

### My "lie detector" question for any metric

Whenever someone proposes a metric, I ask:

> **If this number doubles, what becomes meaningfully easier next month?**

If the answer is "uh… we look good," it's not a metric. It's makeup.

If the answer is "we get more returning builders, more repeat speakers, and more projects formed," now we're talking.

### The builder-focused shift I saw clearly with AI Tinkerers

One of the communities I'm busy building in the Middle East, AI Tinkerers, works when it respects builders. The format is basically a built-in filter:

* show your work
* get feedback
* meet collaborators
* leave with momentum

So yes, we can count RSVPs and attendance. But those aren't the point.

The point is:

* **How many builders returned within 60 days?**
* **How many demos came from first-time attendees?**
* **How many intros led to collaboration (even small ones)?**
* **How many people left with a "next step" that actually happened?**

Those are harder to measure than impressions.
Good. Reality is harder than vibes.

### A metric that actually matters: Returning builders

If I had to choose *one* community metric that predicts health better than almost anything else, it's:

> **Returning builders as a percentage of attendees**

A room full of first-timers can be exciting.
But a room full of returners is a signal: **value is being created.**

Returning builders means:

* they learned something useful
* or met someone valuable
* or felt safe enough to share unfinished work
* or found a reason to keep building

If your community has high attendance and low return rate, you might be hosting a show. Not an ecosystem.

### What "good" measurement looks like

Good DevRel measurement is boring in a very specific way:

* it's consistent
* it tracks a small set of signals
* it leads to decisions
* it exposes tradeoffs
* it forces focus

The end goal isn't "great numbers."
The end goal is:

> **A system where your weekly actions predictably create future capability.**

And that's where the next articles go—because the real unlock isn't picking metrics.

It's building **mechanisms** so those metrics move without heroics.
